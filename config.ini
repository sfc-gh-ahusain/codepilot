[logging]
level = INFO
log_file = codepilot.log

[log_settings]
flush_interval_sec = 10
max_log_size = 1048576
backup_count = 5

# gpt4falcon
# llama3
# all-MiniLM-L6-v2
# microsoft/codebert-base
[model]
llm_model = llama3
transformer = all-MiniLM-L6-v2

[llama3]
path = "/Users/ahusain/Library/Application Support/nomic.ai/GPT4All/Meta-Llama-3-8B-Instruct.Q4_0.gguf"

[gpt4falcon]
path = "/Users/ahusain/Library/Application Support/nomic.ai/GPT4All/gpt4all-falcon-newbpe-q4_0.gguf"

[model_dimensions]
all-MiniLM-L6-v2 = 384
microsoft/codebert-base = 768

[paths]
metadata_dir = "/Users/ahusain/bismillah/hackathon24/metadata"
logs_dir = "/Users/ahusain/bismillah/hackathon24/logs"

[filenames]
checksum_file_name = checksums.json
file_mapping_file_name = file_mappings.json
faiss_index_file_name = faiss_index.bin
cost_estimates_file_name = cost_estimates.json

[pattern]
file_pattern = ["UDP.toml", "EncryptKeyProxy.actor.cpp", "BlobCipher.cpp", "BlobCipher.h", "flow.h", "BlobWorker.h", "BlobWorker.actor.cpp", "TLogInterface.h", "TLogServer.actor.cpp", "S3BlobStore.h", "S3BlobStore.actor.cpp", "CommitProxyInterface.h", "CommitProxyInterface.cpp", "CommitProxyServer.actor.cpp", "ResolverInterface.h", "Resolver.actor.cpp"]